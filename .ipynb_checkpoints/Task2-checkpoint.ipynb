{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32521c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {}\n",
    "\n",
    "for name in [\"train\", \"dev\", \"test\"]:\n",
    "    with open(f\"Data/3class/{name}.json\", \"r\") as filedata:\n",
    "        data[name] = json.load(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa98070",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this cell has 2 functions, one that checks language and one that translates if English\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "# recognizes the language of the text and translates if English\n",
    "def recognizeText(text):\n",
    "    if detect(text) != 'no':\n",
    "        return translateText(text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# translates the text given\n",
    "def translateText(text):\n",
    "    translated = translator.translate(text, src='en', dest='no')\n",
    "    return translated.text\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this cell has 2 functions, one that tokenizes the words for each sentence and one that lemmatizes the words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('norwegian'))\n",
    "\n",
    "# function that 'cleans' the text from the sets, tokenizes and removes stop words and punctuations\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words and token not in punctuation]\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    text = clean_text(text)\n",
    "    return lemmatizer.lemmatize(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text_train = []\n",
    "for row in data[\"train\"]:\n",
    "    text = recognizeText(row[\"text\"])\n",
    "    text = lemmatize(text)\n",
    "    text_train.append(text)\n",
    "\n",
    "text_test = []\n",
    "for row in data[\"test\"]:\n",
    "    text = recognizeText(row[\"text\"])\n",
    "    text_test.append(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_label_list = []\n",
    "for row in data[\"train\"]:\n",
    "    train_label_list.append(row[\"label\"])\n",
    "    \n",
    "test_label_list = []\n",
    "for row in data[\"test\"]:\n",
    "    test_label_list.append(row[\"label\"])\n",
    "    \n",
    "y_train = np.array(train_label_list)\n",
    "y_test = np.array(test_label_list)\n",
    "\n",
    "print(f\"Training label shape: {y_train.shape}\")\n",
    "print(f\"Testing label shape: {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "s_words = stopwords.words(\"norwegian\")\n",
    "print(\"Number of Norwegian stopwords: \" + str(len(s_words)))\n",
    "print(f\"LIST OF STOPWORDS: {s_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e3100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(stop_words=s_words, min_df=2)\n",
    "vec.fit(text_train)\n",
    "X_train = vec.transform(text_train).toarray()\n",
    "X_test = vec.transform(text_test).toarray()\n",
    "\n",
    "print(f\"Vocabulary size: {len(vec.vocabulary_)}\")\n",
    "print(f\"Every 100th word in vocabulary: {vec.get_feature_names_out()[::100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17280c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=75, n_jobs=-1)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4aa8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_pred_1 = logreg.predict(X_train)\n",
    "test_pred_1 = logreg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression first try scores\")\n",
    "print(\"Training score: {:.3f}\".format(accuracy_score(y_train, train_pred_1)))\n",
    "print(\"Test score: {:.3f}\".format(accuracy_score(y_test, test_pred_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dccd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {\"Neutral\": 0, \"Positive\": 0, \"Negative\": 0}\n",
    "for label in train_pred_1:\n",
    "    count_dict[label] += 1\n",
    "    \n",
    "display(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=400, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_2 = rfc.predict(X_train)\n",
    "test_pred_2 = rfc.predict(X_test)\n",
    "\n",
    "print(\"Random Forest scores\")\n",
    "print(\"Training score: {:.3f}\".format(accuracy_score(y_train, train_pred_2)))\n",
    "print(\"Test score: {:.3f}\".format(accuracy_score(y_test, test_pred_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a840881",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 0\n",
    "sum_depth = 0\n",
    "\n",
    "for e in rfc.estimators_:\n",
    "    sum_depth += e.tree_.max_depth\n",
    "    if(e.tree_.max_depth > max_depth):\n",
    "        max_depth = e.tree_.max_depth\n",
    "\n",
    "print(f\"Maximum depth is: {max_depth}\")\n",
    "print(f\"Average depth is: {(sum_depth/len(rfc.estimators_))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30190070",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_3 = mnb.predict(X_train)\n",
    "test_pred_3 = mnb.predict(X_test)\n",
    "\n",
    "print(\"Multinomial Naive Bayes scores\")\n",
    "print(\"Training score: {:.3f}\".format(accuracy_score(y_train, train_pred_3)))\n",
    "print(\"Test score: {:.3f}\".format(accuracy_score(y_test, test_pred_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0f049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}